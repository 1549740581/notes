MySQL 的行锁是在引擎层由各个引擎自己实现的，但并不是所有的引擎都支持行锁。InnoDB 是支持行锁的，这也是 MyISAM 被 InnoDB 替代的重要原因之一。行锁必须有索引才能实现，否则就会自动锁全表，变为表锁。



## 两阶段锁协议

在 InnoDB 事务中，**行锁是在需要的时候才加上**，但并不是不需要了就立刻释放，而是要等到**事务结束时才释放**。这个就是两阶段锁协议。有了两阶段锁设定，在实际开发中一个经验依据：

**如果你的事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁尽量往后放**。

以一个电影院购票业务为例，购票业务设计到两个update操作，一个insert操作：

> 1. 从顾客A账户中扣钱

> 2. 向电影院账户中加钱
> 3. 插入一条日志纪录

这三个操作会被放入到同一个事物中执行，要么全部成功，要么全部失败，并且这三者的顺序对于最终结果没有影响。那么就可以将步骤2尽量往后放，最大程度地减少了事务之间的锁等待，提升了并发度。

但是，将最有可能造成锁冲突，影响并发度的锁往后放在高并发环境下还是会出现问题：服务器CPU处于满负载状态，但是整个数据库的每秒执行的事务却很少，可能出现了死锁问题，正在进行死锁检测。



## 死锁和死锁检测

当并发系统中不同线程出现循环资源依赖，涉及的线程都在等待别的线程释放资源时，就会导致这几个线程都进入无限等待的状态，称为死锁。例如：

|                 事务A                 |             事务B              |
| :-----------------------------------: | :----------------------------: |
| begin; update t set k=k+1 where id=1; |             begin;             |
|                                       | update t set k=k+1 where id=2; |
|    update t set k=k+1 where id=2;     |                                |
|                                       | update t set k=k+1 where id=1; |

- 事务A持有id=1记录的行锁，等待事务B释放id=2的行锁
- 事务B持有id=2记录的行锁，等待事务A释放id=1的行锁

出现死锁之后，一般有两种解决方案：

### 等待直至超时

在InnoDB中，可以通过参数 `innodb_lock_wait_timeout` 参数设置，默认50s。对于在线服务器而言，50s是不能接受的。但是也能不能将该值调的过小，因为可能存在一些简单的锁等待任务。如果参数值简单锁等待时间还要小，会将简单锁等待认为是死锁，导致误伤。

### 主动死锁检测

在InnoDB中，参数 `innodb_deadlock_detect` 默认值本身就是on，主动死锁检测就是在发生死锁时候，会快速发现并进行处理，但是主动死锁检测是有额外负担的。即死锁检测会消耗掉大量的CPU资源，导致CPU满负载，但是每秒却执行不了几个事务。



### 解决热点行更新导致的性能问题？

热点行更新可能导致死锁问题，而死锁检测需要消耗大量的CPU资源，导致性能下降。

- 直接关闭掉死锁检测：如果能保证业务中不会有死锁产生，关闭掉死锁检测是可以的，但是不推荐
- 控制并发度：例如可以控制某一行最多只能有多少个线程进行更新。但是对于热点行而言，这样的控制还是有缺陷的，可以引入中间件技术，或者直接修改MySQL的源码，对热点行进行更新需要先排队才能进入引擎，这样InnoDB内部就不会有大量的死锁检测工作了。
- 将多行数据改成逻辑上的一行数据：例如之前购买电影票的示例中，顾客每购买一张电影票，电影院账户都需要增加m元，而已将十次购买汇总成1次购买，然后电影院账户直接增加10*m元，减少热点行的更新操作。



## 问题

假如需要删除掉表中10000行数据，有一下三种方式可以做到：

- 直接delete from T limit 10000;
- 在一个连接中循环20次：delete from T limit 500;
- 在20个连接中分别执行：delete from T limit 500;

推荐使用第二种。

第一种方案，单个语句占用时间过长，锁的时间也过长，而且大事务还会导致主从延迟；

第三种方案，相当于人为增加并发量，会造成锁冲突。



